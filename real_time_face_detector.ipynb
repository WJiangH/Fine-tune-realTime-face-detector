{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63265dad",
   "metadata": {},
   "source": [
    "## Object Detection with OpenCV-Python Using a Haar-Cascade Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6c9e51",
   "metadata": {},
   "source": [
    "### 1. Package import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aba21ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208d9da9",
   "metadata": {},
   "source": [
    "### 2. CascadeClassifier from cv2, which could be applied in the three method\n",
    "- static capture the face from image\n",
    "- object detction from the video\n",
    "- real-time face detection\n",
    "\n",
    "Part of the following code is referred to [blog](https://stackabuse.com/object-detection-with-opencv-python-using-a-haar-cascade-classifier/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98815739",
   "metadata": {},
   "source": [
    "load the `vgg_model` to classify the objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13630a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = './models/vgg_model.h5'\n",
    "vgg_model = tf.keras.models.load_model(model_name)\n",
    "class_names = ['cats', 'dogs']\n",
    "RED = (0, 0, 255)\n",
    "GREEN = (0, 255, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f37745c",
   "metadata": {},
   "source": [
    "### some functions used in object capture\n",
    "\n",
    "- `imread()`method loads the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c494e234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19353ed8",
   "metadata": {},
   "source": [
    "#### 2.1 static capture the face from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfebda8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469a0993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format image\n",
    "def image_format(image):\n",
    "    image = tf.image.resize(image, [150, 150])\n",
    "    image = np.expand_dims(image, axis = 0)\n",
    "    image = image / 255.\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1297b0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./data/test/cats/cat.12301.jpg\"\n",
    "window_name = f\"Detected Objects in {image_path}\"\n",
    "original_image = cv2.imread(image_path)\n",
    "\n",
    "\n",
    "# Convert the image to grayscale for easier computation\n",
    "image_grey = cv2.cvtColor(original_image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "eye_classifier = cv2.CascadeClassifier(f\"{cv2.data.haarcascades}haarcascade_eye.xml\")\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier(f\"{cv2.data.haarcascades}haarcascade_frontalface_alt.xml\")\n",
    "\n",
    "detected_eyes = eye_classifier.detectMultiScale(image_grey, minSize=(50, 50))\n",
    "detected_face = face_classifier.detectMultiScale(image_grey, minSize=(50, 50))\n",
    "\n",
    "prediction = vgg_model.predict(image_format(original_image))\n",
    "y_pred = class_names[np.array(prediction[0]).argmax(axis=0)]\n",
    "confidence = np.array(prediction[0]).max(axis=0)\n",
    "\n",
    "color = (0, 255, 0) if y_pred == 'cats' else (0, 0, 255)\n",
    "\n",
    "\n",
    "print(y_pred, confidence, color)\n",
    "# Draw rectangles on eyes\n",
    "if len(detected_eyes) != 0:\n",
    "    for (x, y, width, height) in detected_eyes:\n",
    "        cv2.rectangle(original_image, (x, y),\n",
    "                      (x + height, y + width),\n",
    "                      (0, 255, 0), 5)\n",
    "\n",
    "        \n",
    "# Draw rectangles on faces\n",
    "if len(detected_face) != 0:\n",
    "    for (x, y, width, height) in detected_face:\n",
    "        cv2.rectangle(original_image, (x, y),\n",
    "                      (x + height, y + width),\n",
    "                      (255, 0, 0), 5)\n",
    "        \n",
    "        cv2.putText(\"{:6} - {:.2f}%\".format(y_pred, confidence*100),\n",
    "                    (x, y),\n",
    "                    cv2.FONT_HERSHEY_PLAIN,  # font\n",
    "                    2,  # fontScale\n",
    "                    color,\n",
    "                    2)\n",
    "        \n",
    "cv2.namedWindow(window_name, cv2.WINDOW_KEEPRATIO)\n",
    "cv2.imshow(window_name + '(press ESC to exit)', original_image)\n",
    "cv2.resizeWindow(window_name, 400, 400)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Streaming ended\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926a7ded",
   "metadata": {},
   "source": [
    "#### 2.2 detect from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15762a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extended_image(img, x, y, w, h, k=0.1):\n",
    "    '''\n",
    "    Parameters:\n",
    "        img (array-like, 2D): The original image\n",
    "        x (int): x coordinate of the upper-left corner\n",
    "        y (int): y coordinate of the upper-left corner\n",
    "        w (int): Width of the desired image\n",
    "        h (int): Height of the desired image\n",
    "        k (float): The coefficient of expansion of the image\n",
    "    Returns:\n",
    "        image (tensor with shape (1, 150, 150, 3))\n",
    "    '''\n",
    "    # The next code block checks that coordinates will be non-negative\n",
    "    # (in case if desired image is located in top left corner)\n",
    "    \n",
    "    if x - k*w > 0:\n",
    "        start_x = int(x - k*w)\n",
    "    else:\n",
    "        start_x = x\n",
    "    if y - k*h > 0:\n",
    "        start_y = int(y - k*h)\n",
    "    else:\n",
    "        start_y = y\n",
    "\n",
    "    end_x = int(x + (1 + k)*w)\n",
    "    end_y = int(y + (1 + k)*h)\n",
    "\n",
    "    face_image = img[start_y:end_y, start_x:end_x]\n",
    "    face_image = tf.image.resize(face_image, [150, 150])\n",
    "    face_image = np.expand_dims(face_image, axis=0)\n",
    "    return face_image / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d9fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"./video/cat-dog.MP4\"\n",
    "window_name = f\"Detected Objects in {video_path}\"\n",
    "video = cv2.VideoCapture(video_path)\n",
    "\n",
    "obj = 0\n",
    "while True:\n",
    "    # read() returns a boolean alongside the image data if it was successful\n",
    "    ret, frame = video.read()\n",
    "    frame = cv2.flip(frame, 0)\n",
    "    # Quit if no image can be read from the video\n",
    "    if not ret:\n",
    "        break\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "    # Greyscale image for classification\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Define classifier\n",
    "    cascade_classifier = cv2.CascadeClassifier(\n",
    "        f\"{cv2.data.haarcascades}haarcascade_frontalcatface.xml\")\n",
    "    \n",
    "    # Detect objects\n",
    "    detected_objects = cascade_classifier.detectMultiScale(\n",
    "        image, minSize=(50, 50))\n",
    "    \n",
    "    # Draw rectangles\n",
    "    if len(detected_objects) != 0:\n",
    "        for (x, y, height, width) in detected_objects:\n",
    "            \n",
    "            face_image = get_extended_image(frame, x, y, height, width, 0.5)\n",
    "            result = vgg_model.predict(face_image)\n",
    "            prediction = class_names[np.array(result[0]).argmax(axis=0)]\n",
    "            confidence = np.array(result[0]).max(axis=0)\n",
    "            if prediction == 'cats':\n",
    "                color = (0, 255, 0)\n",
    "            else:\n",
    "                color = (0, 0, 255)\n",
    "            \n",
    "            cv2.rectangle(frame, (x, y), ((x + height), (y + width)), color, 5)\n",
    "            \n",
    "            cv2.putText(frame,\n",
    "                    # text to put\n",
    "                    \"{:6} - {:.2f}%\".format(prediction, confidence*100),\n",
    "                    (x, y),\n",
    "                    cv2.FONT_HERSHEY_PLAIN,  # font\n",
    "                    5,  # fontScale\n",
    "                    color,\n",
    "                    5)  # thickness in px\n",
    "            \n",
    "            obj += 1\n",
    "            filePath = \"./example_imgs/video{}.jpg\".format(obj)\n",
    "            cv2.imwrite(filePath, frame)\n",
    "            \n",
    "    #Show image\n",
    "    cv2.imshow(window_name, frame)\n",
    "    \n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa2526d",
   "metadata": {},
   "source": [
    "#### 3. real-time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d54576",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)  # webcamera\n",
    "\n",
    "if not video_capture.isOpened():\n",
    "    print(\"Unable to access the camera\")\n",
    "else:\n",
    "    print(\"Access to the camera was successfully obtained\")\n",
    "\n",
    "print(\"Streaming started - to quit press ESC\")\n",
    "while True:\n",
    "\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=5,\n",
    "        minSize=(100, 100),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # for each face on the image detected by OpenCV\n",
    "        # get extended image of this face\n",
    "        face_image = get_extended_image(frame, x, y, w, h, 0.5)\n",
    "\n",
    "        # classify face and draw a rectangle around the face\n",
    "        # green for positive class and red for negative\n",
    "        result = vgg_model.predict(face_image)\n",
    "        prediction = class_names[np.array(\n",
    "            result[0]).argmax(axis=0)]  # predicted class\n",
    "        confidence = np.array(result[0]).max(axis=0)  # degree of confidence\n",
    "\n",
    "        if prediction == 'cats':\n",
    "            color = GREEN\n",
    "        else:\n",
    "            color = RED\n",
    "        # draw a rectangle around the face\n",
    "        cv2.rectangle(frame,\n",
    "                      (x, y),  # start_point\n",
    "                      (x+w, y+h),  # end_point\n",
    "                      color,\n",
    "                      2)  # thickness in px\n",
    "        cv2.putText(frame,\n",
    "                    # text to put\n",
    "                    \"{:6} - {:.2f}%\".format(prediction, confidence*100),\n",
    "                    (x, y),\n",
    "                    cv2.FONT_HERSHEY_PLAIN,  # font\n",
    "                    2,  # fontScale\n",
    "                    color,\n",
    "                    2)  # thickness in px\n",
    "\n",
    "    # display the resulting frame\n",
    "    cv2.imshow(\"Face detector - to quit press ESC\", frame)\n",
    "\n",
    "    # Exit with ESC\n",
    "    key = cv2.waitKey(1)\n",
    "    if key % 256 == 27:  # ESC code\n",
    "        break\n",
    "\n",
    "\n",
    "# when everything done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Streaming ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea52d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cascade_classifier = cv2.CascadeClassifier(\n",
    "        f\"{cv2.data.haarcascades}haarcascade_frontalface_default.xml\")\n",
    "    \n",
    "window_name = \"Detected Objects in webcam\"\n",
    "video = cv2.VideoCapture(0)\n",
    "obj = 0\n",
    "while video.isOpened():\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    detected_objects = cascade_classifier.detectMultiScale(\n",
    "        image, \n",
    "        scaleFactor=1.3,\n",
    "\n",
    "        minSize=(50, 50),\n",
    "        )\n",
    "    \n",
    "    if len(detected_objects) != 0:\n",
    "        for x, y, height, width in detected_objects:\n",
    "            \n",
    "            face_image = get_extended_image(frame, x, y, height, width, 0.5)\n",
    "            result = vgg_model.predict(face_image)\n",
    "            prediction = class_names[np.array(result[0]).argmax(axis=0)]\n",
    "            confidence = np.array(result[0]).max(axis=0)\n",
    "            if prediction == 'cats':\n",
    "                color = (0, 255, 0)\n",
    "            else:\n",
    "                color = (0, 0, 255)\n",
    "            \n",
    "            cv2.rectangle(frame, (x, y), ((x + height), (y + width)), color, 5)\n",
    "            \n",
    "            cv2.putText(frame,\n",
    "                    # text to put\n",
    "                    \"{:6} - {:.2f}%\".format(prediction, confidence*100),\n",
    "                    (x, y),\n",
    "                    cv2.FONT_HERSHEY_PLAIN,  # font\n",
    "                    5,  # fontScale\n",
    "                    color,\n",
    "                    5)  # thickness in px\n",
    "            \n",
    "            obj += 1\n",
    "            filePath = \"./example_imgs/real_time{}.jpg\".format(obj)\n",
    "            cv2.imwrite(filePath, frame)\n",
    "        \n",
    "    cv2.imshow(window_name, frame)\n",
    "\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Streaming ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559ea3a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
